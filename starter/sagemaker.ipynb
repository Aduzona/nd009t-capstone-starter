{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory Monitoring at Distribution Centers\n",
    "\n",
    "This notebook guides you through building, training, and deploying a machine learning model for **Inventory Monitoring at Distribution Centers** using **AWS SageMaker**. The goal is to create a model that can count the number of objects in bins based on images. This project uses the **Amazon Bin Image Dataset**, which contains images from Amazon Fulfillment Centers showing bins with various objects. \n",
    "\n",
    "The key steps in this project include:\n",
    "1. Data preparation and upload to S3.\n",
    "2. Model training on SageMaker using a custom script (`train.py`).\n",
    "3. Model deployment to a SageMaker endpoint for inference.\n",
    "4. Optional tasks such as hyperparameter tuning, debugging, profiling, and cost analysis.\n",
    "\n",
    "This project focuses on implementing a machine learning engineering pipeline rather than achieving high accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.5)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.34.162)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.162 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "!pip install tqdm boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `train_data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not acessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 1 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [04:40<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 2 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2299/2299 [08:55<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 3 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2666/2666 [10:14<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 4 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [08:59<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 5 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [07:09<00:00,  4.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#import json\n",
    "#import boto3\n",
    "\n",
    "def download_and_arrange_data():\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    for k, v in d.items():\n",
    "        print(f\"Downloading Images with {k} objects\")\n",
    "        directory=os.path.join('train_data', k)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name=os.path.basename(file_path).split('.')[0]+'.jpg'\n",
    "            s3_client.download_file('aft-vbi-pds', os.path.join('bin-images', file_name),\n",
    "                             os.path.join(directory, file_name))\n",
    "\n",
    "download_and_arrange_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this project, we are using the **Amazon Bin Image Dataset**, which contains images of bins from Amazon Fulfillment Centers. Each image shows a bin with one or more items inside, where items are placed randomly. This dataset allows us to build a machine learning model that can classify images based on the number of objects in each bin, which is essential for efficient inventory tracking and management in distribution centers.\n",
    "\n",
    "### Structure of the Dataset\n",
    "Each image in the dataset is associated with a metadata file containing details about the items in the bin. The key information for our project is the `EXPECTED_QUANTITY`, which indicates the number of objects present in each bin. This quantity ranges from **1 to 5 objects**, and we use it to create labeled data for training a classification model with five classes:\n",
    "- **Class 1**: Images with 1 object in the bin\n",
    "- **Class 2**: Images with 2 objects in the bin\n",
    "- **Class 3**: Images with 3 objects in the bin\n",
    "- **Class 4**: Images with 4 objects in the bin\n",
    "- **Class 5**: Images with 5 objects in the bin\n",
    "\n",
    "### Data Preprocessing\n",
    "For this project, the images have been organized into folders by the number of objects (1–5), based on the `EXPECTED_QUANTITY` field in the metadata. We then split the data into training, validation, and test sets to facilitate model evaluation and ensure generalization.\n",
    "\n",
    "This dataset helps us train a classification model to determine the number of items in a bin from an image, enabling automated inventory counting at distribution centers.\n",
    "\n",
    "More information about the dataset can be found [here](https://registry.opendata.aws/amazon-bin-imagery/).\n",
    "\n",
    "This function splits the data into `train`, `validation`, and `test` sets based on the specified ratios. The output directory `processed_data` will contain subdirectories for training, validation, and test sets, each further organized by object count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split for category '1' complete.\n",
      "Data split for category '2' complete.\n",
      "Data split for category '3' complete.\n",
      "Data split for category '4' complete.\n",
      "Data split for category '5' complete.\n"
     ]
    }
   ],
   "source": [
    "#TODO: Perform any data cleaning or data preprocessing\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "def split_data(data_dir, output_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(os.path.join(output_dir, 'train'))\n",
    "    os.makedirs(os.path.join(output_dir, 'validation'))\n",
    "    os.makedirs(os.path.join(output_dir, 'test'))\n",
    "    \n",
    "    for object_count in os.listdir(data_dir):\n",
    "        images = os.listdir(os.path.join(data_dir, object_count))\n",
    "        train, temp = train_test_split(images, train_size=train_ratio)\n",
    "        val, test = train_test_split(temp, train_size=val_ratio/(val_ratio + test_ratio))\n",
    "        \n",
    "        for subset, subset_images in zip(['train', 'validation', 'test'], [train, val, test]):\n",
    "            subset_dir = os.path.join(output_dir, subset, object_count)\n",
    "            os.makedirs(subset_dir, exist_ok=True)\n",
    "            for image in subset_images:\n",
    "                shutil.copy2(os.path.join(data_dir, object_count, image), subset_dir)\n",
    "        print(f\"Data split for category '{object_count}' complete.\")\n",
    "\n",
    "# Run data split\n",
    "split_data('train_data', 'processed_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-eu-west-1-940426109786\n",
      "AWS Region: eu-west-1\n",
      "RoleArn: arn:aws:iam::940426109786:role/service-role/AmazonSageMaker-ExecutionRole-20241111T123978\n",
      "Uploading data to S3 at s3://sagemaker-eu-west-1-940426109786/inventory-monitoring/\n"
     ]
    }
   ],
   "source": [
    "#TODO: Upload the data to AWS S3\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "#import boto3\n",
    "#import os\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket=session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role() #sagemaker iam role\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "data = \"s3://{}/{}/\".format(bucket, \"inventory-monitoring\")\n",
    "print(f\"Uploading data to S3 at {data}\")\n",
    "output = \"s3://{}/{}/\".format(bucket, \"output\")\n",
    "model_dir = \"s3://{}/{}/\".format(bucket, \"model\")\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] =bucket\n",
    "os.environ['SM_CHANNEL_TRAIN']=data \n",
    "os.environ['SM_OUTPUT_DATA_DIR']=output\n",
    "os.environ['SM_MODEL_DIR']=model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_path = session.upload_data(path='processed_data', bucket=bucket, key_prefix=f'inventory-monitoring/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-1-940426109786/output/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important. \n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "# Define hyperparameters for the training job\n",
    "hyperparameters = {\n",
    "    \"batch-size\": 64,\n",
    "    \"epochs\": 3,\n",
    "    \"lr\": 0.1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "# Import the PyTorch estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create a PyTorch Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",                 # Path to the training script\n",
    "    role=role,                              # IAM role with permissions\n",
    "    instance_count=1,                       # Number of instances\n",
    "    instance_type=\"ml.m5.xlarge\",           # Instance type for training\n",
    "    framework_version=\"1.8\",                # PyTorch version\n",
    "    py_version=\"py3\",                       # Python version\n",
    "    hyperparameters=hyperparameters,        # Hyperparameters defined above\n",
    "    output_path=output                      # Path for saving output artifacts\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2024-11-15-22-20-24-440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-15 22:20:25 Starting - Starting the training job...\n",
      "2024-11-15 22:20:39 Starting - Preparing the instances for training...\n",
      "2024-11-15 22:21:04 Downloading - Downloading input data......\n",
      "2024-11-15 22:22:24 Downloading - Downloading the training image...\n",
      "2024-11-15 22:22:35 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,539 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,542 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,551 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,553 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,706 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,720 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,732 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-11-15 22:22:43,742 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 3,\n",
      "        \"lr\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2024-11-15-22-20-24-440\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-940426109786/pytorch-training-2024-11-15-22-20-24-440/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":3,\"lr\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-940426109786/pytorch-training-2024-11-15-22-20-24-440/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":3,\"lr\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2024-11-15-22-20-24-440\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-940426109786/pytorch-training-2024-11-15-22-20-24-440/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"3\",\"--lr\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch-size 64 --epochs 3 --lr 0.1\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:44.610 algo-1:27 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:44.786 algo-1:27 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:45.787 algo-1:27 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:45.788 algo-1:27 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:45.788 algo-1:27 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:45.788 algo-1:27 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:45.790 algo-1:27 INFO hook.py:591] name:fc.weight count_params:10240\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:45.790 algo-1:27 INFO hook.py:591] name:fc.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:45.791 algo-1:27 INFO hook.py:593] Total Trainable Params: 10245\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:46.282 algo-1:27 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-15 22:22:46.285 algo-1:27 INFO hook.py:488] Hook is writing from the hook with pid: 27\u001b[0m\n",
      "\u001b[34mEpoch 1, Training Loss: 23.174151670529803\u001b[0m\n",
      "\u001b[34mValidation Loss: 21.155139185002938, Accuracy: 22.174329501915707%\u001b[0m\n",
      "\u001b[34mEpoch 2, Training Loss: 9.901064793127448\u001b[0m\n",
      "\u001b[34mValidation Loss: 16.998271569292065, Accuracy: 23.132183908045977%\u001b[0m\n",
      "\u001b[34mEpoch 3, Training Loss: 11.891886910025718\u001b[0m\n",
      "\u001b[34mValidation Loss: 13.920588432143932, Accuracy: 28.68773946360153%\u001b[0m\n",
      "\u001b[34mTest Loss: 14.173308691604644, Accuracy: 27.34225621414914%\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015 35%|███▌      | 34.3M/97.8M [00:00<00:00, 360MB/s]#015 70%|███████   | 68.7M/97.8M [00:00<00:00, 317MB/s]#015100%|██████████| 97.8M/97.8M [00:00<00:00, 343MB/s]\u001b[0m\n",
      "\u001b[34m2024-11-15 23:22:57,537 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-15 23:23:11 Uploading - Uploading generated training model\n",
      "2024-11-15 23:23:11 Completed - Training job completed\n",
      "Training seconds: 3726\n",
      "Billable seconds: 3726\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your estimator\n",
    "# Start the training job\n",
    "estimator.fit({\"train\": s3_data_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standout Suggestions\n",
    "You do not need to perform the tasks below to finish your project. However, you can attempt these tasks to turn your project into a more advanced portfolio piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "**TODO:** Here you can perform hyperparameter tuning to increase the performance of your model. You are encouraged to \n",
    "- tune as many hyperparameters as you can to get the best performance from your model\n",
    "- explain why you chose to tune those particular hyperparameters and the ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Profiling and Debugging\n",
    "**TODO:** Use model debugging and profiling to better monitor and debug your model training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and fit an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying\n",
    "**TODO:** Can you deploy your model to an endpoint and then query that endpoint to get a result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheaper Training and Cost Analysis\n",
    "**TODO:** Can you perform a cost analysis of your system and then use spot instances to lessen your model training cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model using a spot instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Instance Training\n",
    "**TODO:** Can you train your model on multiple instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model on Multiple Instances"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
