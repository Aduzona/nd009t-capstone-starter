{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory Monitoring at Distribution Centers\n",
    "\n",
    "This notebook guides you through building, training, and deploying a machine learning model for **Inventory Monitoring at Distribution Centers** using **AWS SageMaker**. The goal is to create a model that can count the number of objects in bins based on images. This project uses the **Amazon Bin Image Dataset**, which contains images from Amazon Fulfillment Centers showing bins with various objects. \n",
    "\n",
    "The key steps in this project include:\n",
    "1. Data preparation and upload to S3.\n",
    "2. Model training on SageMaker using a custom script (`train.py`).\n",
    "3. Model deployment to a SageMaker endpoint for inference.\n",
    "4. Optional tasks such as hyperparameter tuning, debugging, profiling, and cost analysis.\n",
    "\n",
    "This project focuses on implementing a machine learning engineering pipeline rather than achieving high accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.5)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.34.162)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.162 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "!pip install tqdm boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `train_data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not acessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 1 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [01:36<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 2 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2299/2299 [03:05<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 3 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2666/2666 [03:33<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 4 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [03:08<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 5 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [02:25<00:00, 12.91it/s]\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#import json\n",
    "#import boto3\n",
    "\n",
    "def download_and_arrange_data():\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    for k, v in d.items():\n",
    "        print(f\"Downloading Images with {k} objects\")\n",
    "        directory=os.path.join('train_data', k)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name=os.path.basename(file_path).split('.')[0]+'.jpg'\n",
    "            s3_client.download_file('aft-vbi-pds', os.path.join('bin-images', file_name),\n",
    "                             os.path.join(directory, file_name))\n",
    "\n",
    "download_and_arrange_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this project, we are using the **Amazon Bin Image Dataset**, which contains images of bins from Amazon Fulfillment Centers. Each image shows a bin with one or more items inside, where items are placed randomly. This dataset allows us to build a machine learning model that can classify images based on the number of objects in each bin, which is essential for efficient inventory tracking and management in distribution centers.\n",
    "\n",
    "### Structure of the Dataset\n",
    "Each image in the dataset is associated with a metadata file containing details about the items in the bin. The key information for our project is the `EXPECTED_QUANTITY`, which indicates the number of objects present in each bin. This quantity ranges from **1 to 5 objects**, and we use it to create labeled data for training a classification model with five classes:\n",
    "- **Class 1**: Images with 1 object in the bin\n",
    "- **Class 2**: Images with 2 objects in the bin\n",
    "- **Class 3**: Images with 3 objects in the bin\n",
    "- **Class 4**: Images with 4 objects in the bin\n",
    "- **Class 5**: Images with 5 objects in the bin\n",
    "\n",
    "### Data Preprocessing\n",
    "For this project, the images have been organized into folders by the number of objects (1–5), based on the `EXPECTED_QUANTITY` field in the metadata. We then split the data into training, validation, and test sets to facilitate model evaluation and ensure generalization.\n",
    "\n",
    "This dataset helps us train a classification model to determine the number of items in a bin from an image, enabling automated inventory counting at distribution centers.\n",
    "\n",
    "More information about the dataset can be found [here](https://registry.opendata.aws/amazon-bin-imagery/).\n",
    "\n",
    "This function splits the data into `train`, `validation`, and `test` sets based on the specified ratios. The output directory `processed_data` will contain subdirectories for training, validation, and test sets, each further organized by object count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split for category '1' complete.\n",
      "Data split for category '2' complete.\n",
      "Data split for category '3' complete.\n",
      "Data split for category '4' complete.\n",
      "Data split for category '5' complete.\n"
     ]
    }
   ],
   "source": [
    "#TODO: Perform any data cleaning or data preprocessing\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "def split_data(data_dir, output_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(os.path.join(output_dir, 'train'))\n",
    "    os.makedirs(os.path.join(output_dir, 'validation'))\n",
    "    os.makedirs(os.path.join(output_dir, 'test'))\n",
    "    \n",
    "    for object_count in os.listdir(data_dir):\n",
    "        images = os.listdir(os.path.join(data_dir, object_count))\n",
    "        train, temp = train_test_split(images, train_size=train_ratio)\n",
    "        val, test = train_test_split(temp, train_size=val_ratio/(val_ratio + test_ratio))\n",
    "        \n",
    "        for subset, subset_images in zip(['train', 'validation', 'test'], [train, val, test]):\n",
    "            subset_dir = os.path.join(output_dir, subset, object_count)\n",
    "            os.makedirs(subset_dir, exist_ok=True)\n",
    "            for image in subset_images:\n",
    "                shutil.copy2(os.path.join(data_dir, object_count, image), subset_dir)\n",
    "        print(f\"Data split for category '{object_count}' complete.\")\n",
    "\n",
    "# Run data split\n",
    "split_data('train_data', 'processed_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-254792028129\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::254792028129:role/service-role/AmazonSageMaker-ExecutionRole-20241116T170316\n",
      "Uploading data to S3 at s3://sagemaker-us-east-1-254792028129/inventory-monitoring/\n"
     ]
    }
   ],
   "source": [
    "#TODO: Upload the data to AWS S3\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "#import boto3\n",
    "#import os\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket=session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role() #sagemaker iam role\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "data = \"s3://{}/{}/\".format(bucket, \"inventory-monitoring\")\n",
    "print(f\"Uploading data to S3 at {data}\")\n",
    "output = \"s3://{}/{}/\".format(bucket, \"output\")\n",
    "model_dir = \"s3://{}/{}/\".format(bucket, \"model\")\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] =bucket\n",
    "os.environ['SM_CHANNEL_TRAIN']=data \n",
    "os.environ['SM_OUTPUT_DATA_DIR']=output\n",
    "os.environ['SM_MODEL_DIR']=model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_path = session.upload_data(path='processed_data', bucket=bucket, key_prefix=f'inventory-monitoring/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-254792028129/output/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important. \n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model.\n",
    "\n",
    "`train.py`, is simple model, while `benchmark.py` is our benchmark model which is ResNet50.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "# Define hyperparameters for the training job\n",
    "hyperparameters = {\n",
    "    \"batch-size\": 64,\n",
    "    \"epochs\": 5,\n",
    "    \"lr\": 0.005\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "# Import the PyTorch estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create a PyTorch Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",                 # Path to the training script\n",
    "    role=role,                              # IAM role with permissions\n",
    "    instance_count=1,                       # Number of instances\n",
    "    instance_type=\"ml.p3.2xlarge\", #\"ml.m5.xlarge\",           # Instance type for training\n",
    "    framework_version=\"1.8\",                # PyTorch version\n",
    "    py_version=\"py3\",                       # Python version\n",
    "    hyperparameters=hyperparameters,        # Hyperparameters defined above\n",
    "    output_path=output                      # Path for saving output artifacts\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: simple-train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-16 17:47:37 Starting - Starting the training job\n",
      "2024-11-16 17:47:37 Pending - Training job waiting for capacity......\n",
      "2024-11-16 17:48:21 Pending - Preparing the instances for training...\n",
      "2024-11-16 17:49:00 Downloading - Downloading input data...\n",
      "2024-11-16 17:49:30 Downloading - Downloading the training image........................\n",
      "2024-11-16 17:53:18 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-11-16 17:53:37,579 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-16 17:53:37,610 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-16 17:53:37,613 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-16 17:53:37,881 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 5,\n",
      "        \"lr\": 0.005\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"simple-train\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-254792028129/simple-train/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":5,\"lr\":0.005}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-254792028129/simple-train/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":5,\"lr\":0.005},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"simple-train\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-254792028129/simple-train/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"5\",\"--lr\",\"0.005\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.005\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch-size 64 --epochs 5 --lr 0.005\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:39.328 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:39.378 algo-1:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.571 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.572 algo-1:33 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.573 algo-1:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.573 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.575 algo-1:33 INFO hook.py:591] name:fc.0.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.575 algo-1:33 INFO hook.py:591] name:fc.0.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.575 algo-1:33 INFO hook.py:591] name:fc.2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.575 algo-1:33 INFO hook.py:591] name:fc.2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.576 algo-1:33 INFO hook.py:591] name:fc.4.weight count_params:1280\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.576 algo-1:33 INFO hook.py:591] name:fc.4.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:44.576 algo-1:33 INFO hook.py:593] Total Trainable Params: 526341\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:45.170 algo-1:33 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-16 17:53:45.177 algo-1:33 INFO hook.py:488] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34mEpoch 1, Training Loss: 1.526917470305795\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4661661043934437, Accuracy: 31.130268199233715%\u001b[0m\n",
      "\u001b[34mEpoch 2, Training Loss: 1.447081759557754\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4748019770187437, Accuracy: 30.65134099616858%\u001b[0m\n",
      "\u001b[34mEpoch 3, Training Loss: 1.425901677469165\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4904058541374645, Accuracy: 30.17241379310345%\u001b[0m\n",
      "\u001b[34mEpoch 4, Training Loss: 1.4153426267452405\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4765258077460688, Accuracy: 31.082375478927204%\u001b[0m\n",
      "\u001b[34mEpoch 5, Training Loss: 1.3977836064736364\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.475717907207679, Accuracy: 32.71072796934866%\u001b[0m\n",
      "\u001b[34mTest Loss: 1.449474344517943, Accuracy: 32.02676864244742%\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015 27%|██▋       | 26.7M/97.8M [00:00<00:00, 280MB/s]#015 57%|█████▋    | 55.9M/97.8M [00:00<00:00, 295MB/s]#015 87%|████████▋ | 85.1M/97.8M [00:00<00:00, 301MB/s]#015100%|██████████| 97.8M/97.8M [00:00<00:00, 298MB/s]\u001b[0m\n",
      "\u001b[34m2024-11-16 18:00:35,199 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-16 18:00:39 Uploading - Uploading generated training model\n",
      "2024-11-16 18:00:52 Completed - Training job completed\n",
      "Training seconds: 712\n",
      "Billable seconds: 712\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your estimator\n",
    "# Start the training job\n",
    "estimator.fit({\"train\": s3_data_path}, job_name=\"simple-train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "\n",
    "using `benchmark.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: benchmark-train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-16 18:01:33 Starting - Starting the training job......\n",
      "2024-11-16 18:02:28 Pending - Training job waiting for capacity......\n",
      "2024-11-16 18:03:25 Pending - Preparing the instances for training...\n",
      "2024-11-16 18:03:58 Downloading - Downloading input data...\n",
      "2024-11-16 18:04:33 Downloading - Downloading the training image...........................\n",
      "2024-11-16 18:08:41 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-11-16 18:08:58,284 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-16 18:08:58,318 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-16 18:08:58,321 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-16 18:08:58,631 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 5,\n",
      "        \"lr\": 0.005\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"benchmark-train\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-254792028129/benchmark-train/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"benchmark\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"benchmark.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":5,\"lr\":0.005}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=benchmark.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=benchmark\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-254792028129/benchmark-train/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":5,\"lr\":0.005},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"benchmark-train\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-254792028129/benchmark-train/source/sourcedir.tar.gz\",\"module_name\":\"benchmark\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"benchmark.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"5\",\"--lr\",\"0.005\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.005\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 benchmark.py --batch-size 64 --epochs 5 --lr 0.005\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:00.105 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:00.153 algo-1:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:05.512 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:05.513 algo-1:33 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:05.513 algo-1:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:05.514 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:05.516 algo-1:33 INFO hook.py:591] name:fc.weight count_params:10240\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:05.516 algo-1:33 INFO hook.py:591] name:fc.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:05.516 algo-1:33 INFO hook.py:593] Total Trainable Params: 10245\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:06.061 algo-1:33 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-16 18:09:06.064 algo-1:33 INFO hook.py:488] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34mEpoch 1, Training Loss: 1.8138701267080592\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.629697035098898, Accuracy: 27.011494252873565%\u001b[0m\n",
      "\u001b[34mEpoch 2, Training Loss: 1.5589442802418496\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.626710101105701, Accuracy: 29.50191570881226%\u001b[0m\n",
      "\u001b[34mEpoch 3, Training Loss: 1.5575541728202305\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.7675292174478143, Accuracy: 25.57471264367816%\u001b[0m\n",
      "\u001b[34mEpoch 4, Training Loss: 1.4901196321188808\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.7944839302150684, Accuracy: 28.40038314176245%\u001b[0m\n",
      "\u001b[34mEpoch 5, Training Loss: 1.5870011486791138\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.7185955581993893, Accuracy: 27.10727969348659%\u001b[0m\n",
      "\n",
      "2024-11-16 18:16:17 Uploading - Uploading generated training model\n",
      "2024-11-16 18:16:17 Completed - Training job completed\n",
      "\u001b[34mTest Loss: 1.691682866153024, Accuracy: 29.254302103250478%\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015 25%|██▌       | 24.9M/97.8M [00:00<00:00, 261MB/s]#015 54%|█████▍    | 52.6M/97.8M [00:00<00:00, 278MB/s]#015 83%|████████▎ | 81.1M/97.8M [00:00<00:00, 287MB/s]#015100%|██████████| 97.8M/97.8M [00:00<00:00, 285MB/s]\u001b[0m\n",
      "\u001b[34m2024-11-16 18:16:02,474 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 739\n",
      "Billable seconds: 739\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"batch-size\": 64,\n",
    "    \"epochs\": 5,\n",
    "    \"lr\": 0.005\n",
    "}\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create a PyTorch Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"benchmark.py\",                 # Path to the training script\n",
    "    role=role,                              # IAM role with permissions\n",
    "    instance_count=1,                       # Number of instances\n",
    "    instance_type=\"ml.p3.2xlarge\", #\"ml.m5.xlarge\",           # Instance type for training\n",
    "    framework_version=\"1.8\",                # PyTorch version\n",
    "    py_version=\"py3\",                       # Python version\n",
    "    hyperparameters=hyperparameters,        # Hyperparameters defined above\n",
    "    output_path=output                      # Path for saving output artifacts\n",
    ")\n",
    "\n",
    "# Start the training job\n",
    "estimator.fit({\"train\": s3_data_path},job_name=\"benchmark-train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standout Suggestions\n",
    "You do not need to perform the tasks below to finish your project. However, you can attempt these tasks to turn your project into a more advanced portfolio piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "**TODO:** Here you can perform hyperparameter tuning to increase the performance of your model. You are encouraged to \n",
    "- tune as many hyperparameters as you can to get the best performance from your model\n",
    "- explain why you chose to tune those particular hyperparameters and the ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your hyperparameter search space\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.005, 0.05), #CategoricalParameter,\n",
    "    \"batch-size\": CategoricalParameter([32, 64]),\n",
    "    \"epochs\": IntegerParameter(5, 7)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"Test Loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"Test Loss\", \"Regex\": \"Testing Loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=get_execution_role(),\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge'\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,# due to AWS limit, I used 1 instead of 2 or more.\n",
    "    objective_type=objective_type,\n",
    "    early_stopping_type=\"Auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: hpo3-train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your estimator\n",
    "tuner.fit({\"train\": s3_data_path}, job_name=\"hpo3-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-11-16 20:40:22 Starting - Found matching resource for reuse\n",
      "2024-11-16 20:40:22 Downloading - Downloading the training image\n",
      "2024-11-16 20:40:22 Training - Training image download completed. Training in progress.\n",
      "2024-11-16 20:40:22 Uploading - Uploading generated training model\n",
      "2024-11-16 20:40:22 Completed - Resource retained for reuse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"Test Loss\"',\n",
       " 'batch-size': '\"64\"',\n",
       " 'epochs': '5',\n",
       " 'lr': '0.010603903353801389',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"hpo3-train\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-254792028129/hpo3-train/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Find the best hyperparameters\n",
    "\n",
    "best_estimator = tuner.best_estimator()\n",
    "\n",
    "# Get the hyperparameters of the best-trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size \"64\"\n",
      "epochs 5\n",
      "learning rate 0.010603903353801389\n"
     ]
    }
   ],
   "source": [
    "print('batch size '+best_estimator.hyperparameters()['batch-size'])\n",
    "print('epochs '+best_estimator.hyperparameters()['epochs'])\n",
    "print('learning rate '+best_estimator.hyperparameters()['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Profiling and Debugging\n",
    "**TODO:** Use model debugging and profiling to better monitor and debug your model training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:Framework profiling will be deprecated from tensorflow 2.12 and pytorch 2.0 in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "batch_size=int(best_estimator.hyperparameters()['batch-size'].replace('\"',''))\n",
    "epochs=best_estimator.hyperparameters()['epochs']\n",
    "learn_r=best_estimator.hyperparameters()['lr'].replace('\"','')\n",
    "\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "    DebuggerHookConfig,\n",
    "    rule_configs,\n",
    ")\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]\n",
    "\n",
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")\n",
    "\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "\n",
    "#\"num_gpu\":True\n",
    "\n",
    "hyperparameters = {\"epochs\": epochs, \"batch-size\": batch_size, \"test-batch-size\": \"100\", \"lr\": learn_r}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nestimator =PyTorch(\\n    entry_point=\"train_profile_Debug.py\",\\n    #base_job_name=\"sagemaker-dog-breed-pytorch\",\\n    role=get_execution_role(),\\n    instance_count=1,\\n    instance_type=\"ml.p3.2xlarge\",\\n    hyperparameters = hyperparameters,\\n    framework_version = \"1.8\",\\n    py_version=\"py36\",\\n    profiler_config=profiler_config,\\n    debugger_hook_config=hook_config,\\n    rules=rules\\n    \\n)   \\n\\nestimator.fit({\\'train\\': data}, job_name=\"Profile-Debug-train2\")\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "\n",
    "'''\n",
    "estimator =PyTorch(\n",
    "    entry_point=\"train_profile_Debug.py\",\n",
    "    #base_job_name=\"sagemaker-dog-breed-pytorch\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = \"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    profiler_config=profiler_config,\n",
    "    debugger_hook_config=hook_config,\n",
    "    rules=rules\n",
    "    \n",
    ")   \n",
    "\n",
    "estimator.fit({'train': data}, job_name=\"Profile-Debug-train2\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the profiler output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying\n",
    "**TODO:** Can you deploy your model to an endpoint and then query that endpoint to get a result?\n",
    "We will deploy 3 models.\n",
    "\n",
    "* simple-train\n",
    "* benchmark-train\n",
    "* hypo3-train: best from them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "\n",
    "jpeg_serializer = sagemaker.serializers.IdentitySerializer(\"image/jpeg\")\n",
    "json_deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "\n",
    "class ImagePredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(ImagePredictor, self).__init__(\n",
    "            endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            serializer=jpeg_serializer,\n",
    "            deserializer=json_deserializer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "\n",
    "def deploy_model(endpoint_name, model_tar_path):\n",
    "    # Define the model\n",
    "    pytorch_model = PyTorchModel(\n",
    "        model_data= model_tar_path,\n",
    "        role=role,\n",
    "        sagemaker_session=session,\n",
    "        entry_point=\"inference.py\",  # Path to the inference script if needed\n",
    "        framework_version=\"1.8\",\n",
    "        py_version=\"py36\",\n",
    "        predictor_cls=ImagePredictor\n",
    "    )\n",
    "    \n",
    "    # Deploy the model to an endpoint\n",
    "    predictor = pytorch_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.g4dn.xlarge\",#\"ml.m5.xlarge\",\n",
    "        endpoint_name=endpoint_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Model deployed to endpoint: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-254792028129/output/simple-train/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-254792028129/pytorch-inference-2024-11-16-23-52-39-726/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-16-23-52-50-231\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-simple\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-simple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!Model deployed to endpoint: endpoint-simple\n"
     ]
    }
   ],
   "source": [
    "# Simple Model Path\n",
    "trained_model_s3_path = \"s3://sagemaker-us-east-1-254792028129/output/\"\n",
    "model_tar_path = f\"{trained_model_s3_path}simple-train/output/model.tar.gz\"\n",
    "endpoint_name=\"endpoint-simple\"\n",
    "deploy_model(endpoint_name, model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-254792028129/output/benchmark-train/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-254792028129/pytorch-inference-2024-11-16-22-27-51-771/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-16-22-28-01-094\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-resnet\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-resnet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!Model deployed to endpoint: endpoint-resnet\n"
     ]
    }
   ],
   "source": [
    "# Benchmark Model Path\n",
    "trained_model_s3_path = \"s3://sagemaker-us-east-1-254792028129/output/\"\n",
    "model_tar_path = f\"{trained_model_s3_path}benchmark-train/output/model.tar.gz\"\n",
    "endpoint_name=\"endpoint-resnet\"\n",
    "deploy_model(endpoint_name, model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-254792028129/hpo3-train-002-63ec1fb5/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-254792028129/pytorch-inference-2024-11-16-22-35-20-732/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-16-22-35-39-994\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-hpo\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-hpo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!Model deployed to endpoint: endpoint-hpo\n"
     ]
    }
   ],
   "source": [
    "# Tunned Model Path\n",
    "trained_model_s3_path = \"s3://sagemaker-us-east-1-254792028129/\" #\"s3://sagemaker-us-east-1-254792028129/output/\"\n",
    "model_tar_path = f\"{trained_model_s3_path}hpo3-train-002-63ec1fb5/output/model.tar.gz\"\n",
    "endpoint_name=\"endpoint-hpo\"\n",
    "deploy_model(endpoint_name, model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "\n",
    "import numpy as np\n",
    "import io\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def evaluate_endpoint(endpoint_name, test_data_dir, valid_classes, predictor):\n",
    "    \"\"\"\n",
    "    Evaluates an endpoint using the provided test dataset.\n",
    "    \n",
    "    Args:\n",
    "        endpoint_name (str): The name of the SageMaker endpoint to evaluate.\n",
    "        test_data_dir (str): Path to the test dataset directory.\n",
    "        valid_classes (list): List of valid class labels.\n",
    "        predictor: SageMaker predictor object for making predictions.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing accuracy, confusion matrix, and classification report.\n",
    "    \"\"\"\n",
    "    # Preprocessing pipeline for local testing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load the test dataset\n",
    "    test_dataset = ImageFolder(root=test_data_dir, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Initialize lists to store true labels and predictions\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    # Evaluate predictions\n",
    "    for inputs, labels in test_loader:\n",
    "        # Convert the image to raw bytes\n",
    "        raw_image = transforms.ToPILImage()(inputs.squeeze(0))  # Convert tensor to PIL Image\n",
    "        with io.BytesIO() as buffer:\n",
    "            raw_image.save(buffer, format=\"JPEG\")  # Save as JPEG to bytes buffer\n",
    "            payload = buffer.getvalue()  # Get raw bytes\n",
    "\n",
    "        # Make predictions via the endpoint\n",
    "        pred = predictor.predict(payload, initial_args={\"ContentType\": \"image/jpeg\"})\n",
    "        print(f\"Raw prediction response for endpoint {endpoint_name}: {pred}\")  # Debugging raw predictions\n",
    "        pred_class = int(np.argmax(np.array(pred))) + 1  # Adjust the class index to match 1–5 range\n",
    "\n",
    "        # Append true label and prediction\n",
    "        true_labels.append(labels.item() + 1)  # Adjust from 0–4 to 1–5\n",
    "        predictions.append(pred_class)\n",
    "\n",
    "    # Validate class range\n",
    "    print(f\"Unique true labels for endpoint {endpoint_name}: {set(true_labels)}\")\n",
    "    print(f\"Unique predicted labels for endpoint {endpoint_name}: {set(predictions)}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions, labels=list(valid_classes))\n",
    "    classification_report_str = classification_report(\n",
    "        true_labels,\n",
    "        predictions,\n",
    "        labels=list(valid_classes),  # Explicitly specify valid classes\n",
    "        target_names=test_dataset.classes\n",
    "    )\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Accuracy for endpoint {endpoint_name}: {accuracy * 100:.2f}%\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "\n",
    "    # Return the results\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"classification_report\": classification_report_str\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating endpoint-simple...\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-simple in account 254792028129 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m predictor\u001b[38;5;241m=\u001b[39mPredictor(endpoint_name)\n\u001b[0;32m---> 18\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[65], line 47\u001b[0m, in \u001b[0;36mevaluate_endpoint\u001b[0;34m(endpoint_name, test_data_dir, valid_classes, predictor)\u001b[0m\n\u001b[1;32m     44\u001b[0m     payload \u001b[38;5;241m=\u001b[39m buffer\u001b[38;5;241m.\u001b[39mgetvalue()  \u001b[38;5;66;03m# Get raw bytes\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Make predictions via the endpoint\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContentType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage/jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw prediction response for endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Debugging raw predictions\u001b[39;00m\n\u001b[1;32m     49\u001b[0m pred_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39marray(pred))) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Adjust the class index to match 1–5 range\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/base_predictor.py:212\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id, custom_attributes, component_name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_component_name:\n\u001b[1;32m    210\u001b[0m     request_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInferenceComponentName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m inference_component_name\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/botocore/client.py:1017\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1014\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1016\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/endpoint-simple in account 254792028129 for more information."
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "# Replace these with the actual endpoint names and valid classes\n",
    "#endpoints = [\"endpoint-simple\",\"endpoint-resnet\", \"endpoint-hpo\"]\n",
    "test_data_dir = \"processed_data/test\"\n",
    "valid_classes = [1, 2, 3, 4, 5]\n",
    "\n",
    "'''\n",
    "for endpoint_name in endpoints:\n",
    "    print(f\"Evaluating {endpoint_name}...\")\n",
    "    predictor = Predictor(endpoint_name)\n",
    "    results = evaluate_endpoint(endpoint_name, test_data_dir, valid_classes, predictor)\n",
    "    print(f\"Results for {endpoint_name}: {results}\")\n",
    "''' \n",
    "endpoint_name= \"endpoint-simple\"\n",
    "print(f\"Evaluating {endpoint_name}...\")\n",
    "predictor=Predictor(endpoint_name)\n",
    "results = evaluate_endpoint(endpoint_name, test_data_dir, valid_classes, predictor)\n",
    "print(f\"Results for {endpoint_name}: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheaper Training and Cost Analysis\n",
    "**TODO:** Can you perform a cost analysis of your system and then use spot instances to lessen your model training cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model using a spot instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Instance Training\n",
    "**TODO:** Can you train your model on multiple instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train your model on Multiple Instances"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
