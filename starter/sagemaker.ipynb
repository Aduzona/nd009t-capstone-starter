{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory Monitoring at Distribution Centers\n",
    "\n",
    "This notebook guides you through building, training, and deploying a machine learning model for **Inventory Monitoring at Distribution Centers** using **AWS SageMaker**. The goal is to create a model that can count the number of objects in bins based on images. This project uses the **Amazon Bin Image Dataset**, which contains images from Amazon Fulfillment Centers showing bins with various objects. \n",
    "\n",
    "The key steps in this project include:\n",
    "1. Data preparation and upload to S3.\n",
    "2. Model training on SageMaker using a custom script (`train.py`).\n",
    "3. Model deployment to a SageMaker endpoint for inference.\n",
    "4. Optional tasks such as hyperparameter tuning, debugging, profiling, and cost analysis.\n",
    "\n",
    "This project focuses on implementing a machine learning engineering pipeline rather than achieving high accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.5)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.11/site-packages (1.34.162)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.162 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.162->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "!pip install tqdm boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "**TODO:** Run the cell below to download the data.\n",
    "\n",
    "The cell below creates a folder called `train_data`, downloads training data and arranges it in subfolders. Each of these subfolders contain images where the number of objects is equal to the name of the folder. For instance, all images in folder `1` has images with 1 object in them. Images are not divided into training, testing or validation sets. If you feel like the number of samples are not enough, you can always download more data (instructions for that can be found [here](https://registry.opendata.aws/amazon-bin-imagery/)). However, we are not acessing you on the accuracy of your final trained model, but how you create your machine learning engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 1 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1228/1228 [01:36<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 2 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2299/2299 [03:05<00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 3 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2666/2666 [03:33<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 4 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2373/2373 [03:08<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Images with 5 objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [02:25<00:00, 12.91it/s]\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#import json\n",
    "#import boto3\n",
    "\n",
    "def download_and_arrange_data():\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    with open('file_list.json', 'r') as f:\n",
    "        d=json.load(f)\n",
    "\n",
    "    for k, v in d.items():\n",
    "        print(f\"Downloading Images with {k} objects\")\n",
    "        directory=os.path.join('train_data', k)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        for file_path in tqdm(v):\n",
    "            file_name=os.path.basename(file_path).split('.')[0]+'.jpg'\n",
    "            s3_client.download_file('aft-vbi-pds', os.path.join('bin-images', file_name),\n",
    "                             os.path.join(directory, file_name))\n",
    "\n",
    "download_and_arrange_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this project, we are using the **Amazon Bin Image Dataset**, which contains images of bins from Amazon Fulfillment Centers. Each image shows a bin with one or more items inside, where items are placed randomly. This dataset allows us to build a machine learning model that can classify images based on the number of objects in each bin, which is essential for efficient inventory tracking and management in distribution centers.\n",
    "\n",
    "### Structure of the Dataset\n",
    "Each image in the dataset is associated with a metadata file containing details about the items in the bin. The key information for our project is the `EXPECTED_QUANTITY`, which indicates the number of objects present in each bin. This quantity ranges from **1 to 5 objects**, and we use it to create labeled data for training a classification model with five classes:\n",
    "- **Class 1**: Images with 1 object in the bin\n",
    "- **Class 2**: Images with 2 objects in the bin\n",
    "- **Class 3**: Images with 3 objects in the bin\n",
    "- **Class 4**: Images with 4 objects in the bin\n",
    "- **Class 5**: Images with 5 objects in the bin\n",
    "\n",
    "### Data Preprocessing\n",
    "For this project, the images have been organized into folders by the number of objects (1–5), based on the `EXPECTED_QUANTITY` field in the metadata. We then split the data into training, validation, and test sets to facilitate model evaluation and ensure generalization.\n",
    "\n",
    "This dataset helps us train a classification model to determine the number of items in a bin from an image, enabling automated inventory counting at distribution centers.\n",
    "\n",
    "More information about the dataset can be found [here](https://registry.opendata.aws/amazon-bin-imagery/).\n",
    "\n",
    "This function splits the data into `train`, `validation`, and `test` sets based on the specified ratios. The output directory `processed_data` will contain subdirectories for training, validation, and test sets, each further organized by object count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split for category '1' complete.\n",
      "Data split for category '2' complete.\n",
      "Data split for category '3' complete.\n",
      "Data split for category '4' complete.\n",
      "Data split for category '5' complete.\n"
     ]
    }
   ],
   "source": [
    "#TODO: Perform any data cleaning or data preprocessing\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "def split_data(data_dir, output_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(os.path.join(output_dir, 'train'))\n",
    "    os.makedirs(os.path.join(output_dir, 'validation'))\n",
    "    os.makedirs(os.path.join(output_dir, 'test'))\n",
    "    \n",
    "    for object_count in os.listdir(data_dir):\n",
    "        images = os.listdir(os.path.join(data_dir, object_count))\n",
    "        train, temp = train_test_split(images, train_size=train_ratio)\n",
    "        val, test = train_test_split(temp, train_size=val_ratio/(val_ratio + test_ratio))\n",
    "        \n",
    "        for subset, subset_images in zip(['train', 'validation', 'test'], [train, val, test]):\n",
    "            subset_dir = os.path.join(output_dir, subset, object_count)\n",
    "            os.makedirs(subset_dir, exist_ok=True)\n",
    "            for image in subset_images:\n",
    "                shutil.copy2(os.path.join(data_dir, object_count, image), subset_dir)\n",
    "        print(f\"Data split for category '{object_count}' complete.\")\n",
    "\n",
    "# Run data split\n",
    "split_data('train_data', 'processed_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-254792028129\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::254792028129:role/service-role/AmazonSageMaker-ExecutionRole-20241116T170316\n",
      "Uploading data to S3 at s3://sagemaker-us-east-1-254792028129/inventory-monitoring/\n"
     ]
    }
   ],
   "source": [
    "#TODO: Upload the data to AWS S3\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "#import boto3\n",
    "#import os\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket=session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role() #sagemaker iam role\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "\n",
    "data = \"s3://{}/{}/\".format(bucket, \"inventory-monitoring\")\n",
    "print(f\"Uploading data to S3 at {data}\")\n",
    "output = \"s3://{}/{}/\".format(bucket, \"output\")\n",
    "model_dir = \"s3://{}/{}/\".format(bucket, \"model\")\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] =bucket\n",
    "os.environ['SM_CHANNEL_TRAIN']=data \n",
    "os.environ['SM_OUTPUT_DATA_DIR']=output\n",
    "os.environ['SM_MODEL_DIR']=model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_path = session.upload_data(path='processed_data', bucket=bucket, key_prefix=f'inventory-monitoring/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-254792028129/output/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_data_path=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "**TODO:** This is the part where you can train a model. The type or architecture of the model you use is not important. \n",
    "\n",
    "**Note:** You will need to use the `train.py` script to train your model.\n",
    "\n",
    "`train.py`, is simple model, while `benchmark.py` is our benchmark model which is ResNet50.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your model training hyperparameter.\n",
    "#NOTE: You do not need to do hyperparameter tuning. You can use fixed hyperparameter values\n",
    "# Define hyperparameters for the training job\n",
    "hyperparameters = {\n",
    "    \"batch-size\": 64,\n",
    "    \"epochs\": 5,\n",
    "    \"lr\": 0.005\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "# Import the PyTorch estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create a PyTorch Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",                 # Path to the training script\n",
    "    role=role,                              # IAM role with permissions\n",
    "    instance_count=1,                       # Number of instances\n",
    "    instance_type=\"ml.p3.2xlarge\", #\"ml.m5.xlarge\",           # Instance type for training\n",
    "    framework_version=\"1.8\",                # PyTorch version\n",
    "    py_version=\"py3\",                       # Python version\n",
    "    hyperparameters=hyperparameters,        # Hyperparameters defined above\n",
    "    output_path=output                      # Path for saving output artifacts\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: simple-train2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 15:53:46 Starting - Starting the training job\n",
      "2024-11-17 15:53:46 Pending - Training job waiting for capacity...\n",
      "2024-11-17 15:54:21 Pending - Preparing the instances for training......\n",
      "2024-11-17 15:55:11 Downloading - Downloading input data...\n",
      "2024-11-17 15:55:41 Downloading - Downloading the training image........................\n",
      "2024-11-17 15:59:54 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-11-17 16:00:06,809 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-17 16:00:06,841 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-17 16:00:06,844 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-17 16:00:07,134 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 5,\n",
      "        \"lr\": 0.005\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"simple-train2\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-254792028129/simple-train2/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":5,\"lr\":0.005}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-254792028129/simple-train2/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":5,\"lr\":0.005},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"simple-train2\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-254792028129/simple-train2/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"5\",\"--lr\",\"0.005\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.005\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --batch-size 64 --epochs 5 --lr 0.005\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:08.592 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:08.639 algo-1:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.353 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.354 algo-1:33 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.355 algo-1:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.355 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.357 algo-1:33 INFO hook.py:591] name:fc.0.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.357 algo-1:33 INFO hook.py:591] name:fc.0.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.357 algo-1:33 INFO hook.py:591] name:fc.2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.357 algo-1:33 INFO hook.py:591] name:fc.2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.358 algo-1:33 INFO hook.py:591] name:fc.4.weight count_params:1280\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.358 algo-1:33 INFO hook.py:591] name:fc.4.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.358 algo-1:33 INFO hook.py:593] Total Trainable Params: 526341\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.962 algo-1:33 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:00:14.966 algo-1:33 INFO hook.py:488] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34mEpoch 1, Training Loss: 1.5228286663125636\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4585629998495753, Accuracy: 32.18390804597701%\u001b[0m\n",
      "\u001b[34mEpoch 2, Training Loss: 1.4485244041137204\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.457425257255291, Accuracy: 31.84865900383142%\u001b[0m\n",
      "\u001b[34mEpoch 3, Training Loss: 1.4191861589711587\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4860768697270945, Accuracy: 31.561302681992338%\u001b[0m\n",
      "\u001b[34mEpoch 4, Training Loss: 1.4071161649092385\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4892321496174252, Accuracy: 29.50191570881226%\u001b[0m\n",
      "\u001b[34mEpoch 5, Training Loss: 1.4014609269180913\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.4783131363748134, Accuracy: 32.327586206896555%\u001b[0m\n",
      "\u001b[34mTest Loss: 1.4491589372518185, Accuracy: 30.40152963671128%\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015 25%|██▌       | 24.8M/97.8M [00:00<00:00, 260MB/s]#015 54%|█████▍    | 53.1M/97.8M [00:00<00:00, 281MB/s]#015 83%|████████▎ | 81.3M/97.8M [00:00<00:00, 288MB/s]#015100%|██████████| 97.8M/97.8M [00:00<00:00, 287MB/s]\u001b[0m\n",
      "\u001b[34m2024-11-17 16:07:08,713 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-17 16:07:28 Uploading - Uploading generated training model\n",
      "2024-11-17 16:07:28 Completed - Training job completed\n",
      "Training seconds: 737\n",
      "Billable seconds: 737\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your estimator\n",
    "# Start the training job\n",
    "estimator.fit({\"train\": s3_data_path}, job_name=\"simple-train2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Model\n",
    "\n",
    "using `benchmark.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: benchmark-train2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-17 16:08:25 Starting - Starting the training job...\n",
      "2024-11-17 16:08:55 Pending - Training job waiting for capacity...\n",
      "2024-11-17 16:09:18 Pending - Preparing the instances for training...\n",
      "2024-11-17 16:09:54 Downloading - Downloading input data...\n",
      "2024-11-17 16:10:24 Downloading - Downloading the training image........................\n",
      "2024-11-17 16:14:27 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-11-17 16:14:43,136 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-17 16:14:43,167 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-17 16:14:43,170 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-17 16:14:43,453 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 5,\n",
      "        \"lr\": 0.005\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"benchmark-train2\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-254792028129/benchmark-train2/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"benchmark\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"benchmark.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":64,\"epochs\":5,\"lr\":0.005}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=benchmark.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=benchmark\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-254792028129/benchmark-train2/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":5,\"lr\":0.005},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"benchmark-train2\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-254792028129/benchmark-train2/source/sourcedir.tar.gz\",\"module_name\":\"benchmark\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"benchmark.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"5\",\"--lr\",\"0.005\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.005\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 benchmark.py --batch-size 64 --epochs 5 --lr 0.005\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:44.883 algo-1:33 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:44.929 algo-1:33 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:49.839 algo-1:33 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:49.840 algo-1:33 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:49.841 algo-1:33 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:49.841 algo-1:33 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:49.843 algo-1:33 INFO hook.py:591] name:fc.weight count_params:10240\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:49.844 algo-1:33 INFO hook.py:591] name:fc.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:49.844 algo-1:33 INFO hook.py:593] Total Trainable Params: 10245\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:50.387 algo-1:33 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2024-11-17 16:14:50.391 algo-1:33 INFO hook.py:488] Hook is writing from the hook with pid: 33\u001b[0m\n",
      "\u001b[34mEpoch 1, Training Loss: 1.769036815237278\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.6482947448204304, Accuracy: 30.3639846743295%\u001b[0m\n",
      "\u001b[34mEpoch 2, Training Loss: 1.5922006847790888\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.6180672659271065, Accuracy: 27.155172413793103%\u001b[0m\n",
      "\u001b[34mEpoch 3, Training Loss: 1.4788121458474892\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.7756794759596901, Accuracy: 29.07088122605364%\u001b[0m\n",
      "\u001b[34mEpoch 4, Training Loss: 1.5169578302374809\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.5660731075367251, Accuracy: 28.97509578544061%\u001b[0m\n",
      "\u001b[34mEpoch 5, Training Loss: 1.4781749441993373\u001b[0m\n",
      "\u001b[34mValidation Loss: 1.6370537568782937, Accuracy: 28.06513409961686%\u001b[0m\n",
      "\u001b[34mTest Loss: 1.5987685002514782, Accuracy: 30.11472275334608%\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015 28%|██▊       | 27.8M/97.8M [00:00<00:00, 292MB/s]#015 60%|█████▉    | 58.2M/97.8M [00:00<00:00, 308MB/s]#015 91%|█████████ | 88.7M/97.8M [00:00<00:00, 313MB/s]#015100%|██████████| 97.8M/97.8M [00:00<00:00, 310MB/s]\u001b[0m\n",
      "\u001b[34m2024-11-17 16:21:39,401 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-17 16:21:59 Uploading - Uploading generated training model\n",
      "2024-11-17 16:21:59 Completed - Training job completed\n",
      "Training seconds: 724\n",
      "Billable seconds: 724\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"batch-size\": 64,\n",
    "    \"epochs\": 5,\n",
    "    \"lr\": 0.005\n",
    "}\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Create a PyTorch Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"benchmark.py\",                 # Path to the training script\n",
    "    role=role,                              # IAM role with permissions\n",
    "    instance_count=1,                       # Number of instances\n",
    "    instance_type=\"ml.p3.2xlarge\", #\"ml.m5.xlarge\",           # Instance type for training\n",
    "    framework_version=\"1.8\",                # PyTorch version\n",
    "    py_version=\"py3\",                       # Python version\n",
    "    hyperparameters=hyperparameters,        # Hyperparameters defined above\n",
    "    output_path=output                      # Path for saving output artifacts\n",
    ")\n",
    "\n",
    "# Start the training job\n",
    "estimator.fit({\"train\": s3_data_path},job_name=\"benchmark-train2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standout Suggestions\n",
    "You do not need to perform the tasks below to finish your project. However, you can attempt these tasks to turn your project into a more advanced portfolio piece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "**TODO:** Here you can perform hyperparameter tuning to increase the performance of your model. You are encouraged to \n",
    "- tune as many hyperparameters as you can to get the best performance from your model\n",
    "- explain why you chose to tune those particular hyperparameters and the ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your hyperparameter search space\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.005, 0.05), #CategoricalParameter,\n",
    "    \"batch-size\": CategoricalParameter([32, 64]),\n",
    "    \"epochs\": IntegerParameter(5, 7)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"Test Loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"Test Loss\", \"Regex\": \"Testing Loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create your training estimator\n",
    "\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=get_execution_role(),\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p3.2xlarge'\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,# due to AWS limit, I used 1 instead of 2 or more.\n",
    "    objective_type=objective_type,\n",
    "    early_stopping_type=\"Auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: hpo-train2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit your estimator\n",
    "tuner.fit({\"train\": s3_data_path}, job_name=\"hpo-train2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-11-17 16:37:19 Starting - Starting the training job\n",
      "2024-11-17 16:37:19 Pending - Preparing the instances for training\n",
      "2024-11-17 16:37:19 Downloading - Downloading the training image\n",
      "2024-11-17 16:37:19 Training - Training image download completed. Training in progress.\n",
      "2024-11-17 16:37:19 Uploading - Uploading generated training model\n",
      "2024-11-17 16:37:19 Completed - Resource reused by training job: hpo-train2-002-ca095af7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_tuning_objective_metric': '\"Test Loss\"',\n",
       " 'batch-size': '\"64\"',\n",
       " 'epochs': '5',\n",
       " 'lr': '0.02852576380758002',\n",
       " 'sagemaker_container_log_level': '20',\n",
       " 'sagemaker_estimator_class_name': '\"PyTorch\"',\n",
       " 'sagemaker_estimator_module': '\"sagemaker.pytorch.estimator\"',\n",
       " 'sagemaker_job_name': '\"hpo-train2\"',\n",
       " 'sagemaker_program': '\"hpo.py\"',\n",
       " 'sagemaker_region': '\"us-east-1\"',\n",
       " 'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-254792028129/hpo-train2/source/sourcedir.tar.gz\"'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Find the best hyperparameters\n",
    "\n",
    "best_estimator = tuner.best_estimator()\n",
    "\n",
    "# Get the hyperparameters of the best-trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size \"64\"\n",
      "epochs 5\n",
      "learning rate 0.02852576380758002\n"
     ]
    }
   ],
   "source": [
    "print('batch size '+best_estimator.hyperparameters()['batch-size'])\n",
    "print('epochs '+best_estimator.hyperparameters()['epochs'])\n",
    "print('learning rate '+best_estimator.hyperparameters()['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deploying and Querying\n",
    "**TODO:** Can you deploy your model to an endpoint and then query that endpoint to get a result?\n",
    "We will deploy 3 models.\n",
    "\n",
    "* simple-train2\n",
    "* benchmark-train2:\n",
    "* hypo3-train: best from them\n",
    "\n",
    "The function deploy_model_benchmark(...) only used by benchmark-train2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "\n",
    "jpeg_serializer = sagemaker.serializers.IdentitySerializer(\"image/jpeg\")\n",
    "json_deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "\n",
    "class ImagePredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(ImagePredictor, self).__init__(\n",
    "            endpoint_name,\n",
    "            sagemaker_session=sagemaker_session,\n",
    "            serializer=jpeg_serializer,\n",
    "            deserializer=json_deserializer,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "\n",
    "def deploy_model(endpoint_name, model_tar_path):\n",
    "    # Define the model\n",
    "    pytorch_model = PyTorchModel(\n",
    "        model_data= model_tar_path,\n",
    "        role=role,\n",
    "        sagemaker_session=session,\n",
    "        entry_point=\"inference.py\",  # Path to the inference script if needed\n",
    "        framework_version=\"1.8\",\n",
    "        py_version=\"py36\",\n",
    "        predictor_cls=ImagePredictor\n",
    "    )\n",
    "    \n",
    "    # Deploy the model to an endpoint\n",
    "    predictor = pytorch_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        endpoint_name=endpoint_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Model deployed to endpoint: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-254792028129/output/simple-train2/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-254792028129/pytorch-inference-2024-11-17-23-06-02-292/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-17-23-06-13-153\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-simple\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-simple\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!Model deployed to endpoint: endpoint-simple\n"
     ]
    }
   ],
   "source": [
    "# Simple Model Path\n",
    "trained_model_s3_path = \"s3://sagemaker-us-east-1-254792028129/output/\"\n",
    "model_tar_path = f\"{trained_model_s3_path}simple-train2/output/model.tar.gz\"\n",
    "endpoint_name=\"endpoint-simple\"\n",
    "deploy_model(endpoint_name, model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-254792028129/output/benchmark-train2/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-254792028129/pytorch-inference-2024-11-17-23-12-19-002/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-17-23-12-27-617\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-resnet\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-resnet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!Model deployed to endpoint: endpoint-resnet\n"
     ]
    }
   ],
   "source": [
    "# Benchmark Model Path\n",
    "def deploy_model_benchmark(endpoint_name, model_tar_path):\n",
    "    # Define the model\n",
    "    pytorch_model = PyTorchModel(\n",
    "        model_data= model_tar_path,\n",
    "        role=role,\n",
    "        sagemaker_session=session,\n",
    "        entry_point=\"inference_benchmark.py\",  # Path to the inference script if needed\n",
    "        framework_version=\"1.8\",\n",
    "        py_version=\"py36\",\n",
    "        predictor_cls=ImagePredictor\n",
    "    )\n",
    "    \n",
    "    # Deploy the model to an endpoint\n",
    "    predictor = pytorch_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        endpoint_name=endpoint_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Model deployed to endpoint: {predictor.endpoint_name}\")\n",
    "trained_model_s3_path = \"s3://sagemaker-us-east-1-254792028129/output/\"\n",
    "model_tar_path = f\"{trained_model_s3_path}benchmark-train2/output/model.tar.gz\"\n",
    "endpoint_name=\"endpoint-resnet\"\n",
    "deploy_model_benchmark(endpoint_name, model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-254792028129/hpo-train2-001-369f35fa/output/model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-254792028129/pytorch-inference-2024-11-17-19-41-13-799/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2024-11-17-19-41-24-330\n",
      "INFO:sagemaker:Creating endpoint-config with name endpoint-hpo\n",
      "INFO:sagemaker:Creating endpoint with name endpoint-hpo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!Model deployed to endpoint: endpoint-hpo\n"
     ]
    }
   ],
   "source": [
    "# Tunned Model Path\n",
    "def deploy_model_hpo(endpoint_name, model_tar_path):\n",
    "    # Define the model\n",
    "    pytorch_model = PyTorchModel(\n",
    "        model_data= model_tar_path,\n",
    "        role=role,\n",
    "        sagemaker_session=session,\n",
    "        entry_point=\"inference_hpo.py\",  # Path to the inference script if needed\n",
    "        framework_version=\"1.8\",\n",
    "        py_version=\"py36\",\n",
    "        predictor_cls=ImagePredictor\n",
    "    )\n",
    "    \n",
    "    # Deploy the model to an endpoint\n",
    "    predictor = pytorch_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        endpoint_name=endpoint_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Model deployed to endpoint: {predictor.endpoint_name}\")\n",
    "trained_model_s3_path = \"s3://sagemaker-us-east-1-254792028129/\" #\"s3://sagemaker-us-east-1-254792028129/output/\"\n",
    "model_tar_path = f\"{trained_model_s3_path}hpo-train2-001-369f35fa/output/model.tar.gz\"\n",
    "endpoint_name=\"endpoint-hpo\"\n",
    "deploy_model_hpo(endpoint_name, model_tar_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating endpoint-resnet...\n",
      "Unique true labels: {1, 2, 3, 4, 5}\n",
      "Unique predicted labels: {1, 2, 3, 4, 5}\n",
      "Accuracy for endpoint-resnet: 27.53%\n",
      "Confusion Matrix for endpoint-resnet:\n",
      "[[ 36   3  34  42   8]\n",
      " [ 11   5  46 112  56]\n",
      " [  5   1  40 132  89]\n",
      " [  2   1  33 120  82]\n",
      " [  2   0  24  75  87]]\n",
      "Classification Report for endpoint-resnet:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.29      0.40       123\n",
      "           2       0.50      0.02      0.04       230\n",
      "           3       0.23      0.15      0.18       267\n",
      "           4       0.25      0.50      0.33       238\n",
      "           5       0.27      0.46      0.34       188\n",
      "\n",
      "    accuracy                           0.28      1046\n",
      "   macro avg       0.38      0.29      0.26      1046\n",
      "weighted avg       0.35      0.28      0.24      1046\n",
      "\n",
      "Evaluating endpoint-simple...\n",
      "Unique true labels: {1, 2, 3, 4, 5}\n",
      "Unique predicted labels: {1, 2, 3, 4, 5}\n",
      "Accuracy for endpoint-simple: 28.68%\n",
      "Confusion Matrix for endpoint-simple:\n",
      "[[  7  54  54   7   1]\n",
      " [  1  38 124  48  19]\n",
      " [  1  14 132  98  22]\n",
      " [  1   9 123  77  28]\n",
      " [  1   5  63  73  46]]\n",
      "Classification Report for endpoint-simple:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.06      0.10       123\n",
      "           2       0.32      0.17      0.22       230\n",
      "           3       0.27      0.49      0.35       267\n",
      "           4       0.25      0.32      0.28       238\n",
      "           5       0.40      0.24      0.30       188\n",
      "\n",
      "    accuracy                           0.29      1046\n",
      "   macro avg       0.37      0.26      0.25      1046\n",
      "weighted avg       0.34      0.29      0.27      1046\n",
      "\n",
      "Evaluating endpoint-hpo...\n",
      "Unique true labels: {1, 2, 3, 4, 5}\n",
      "Unique predicted labels: {1, 2, 3, 4, 5}\n",
      "Accuracy for endpoint-hpo: 30.98%\n",
      "Confusion Matrix for endpoint-hpo:\n",
      "[[ 60  49   2   3   9]\n",
      " [ 28 104   5  20  73]\n",
      " [ 16  98   8  19 126]\n",
      " [  7  60   1  22 148]\n",
      " [  6  34   3  15 130]]\n",
      "Classification Report for endpoint-hpo:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.49      0.50       123\n",
      "           2       0.30      0.45      0.36       230\n",
      "           3       0.42      0.03      0.06       267\n",
      "           4       0.28      0.09      0.14       238\n",
      "           5       0.27      0.69      0.39       188\n",
      "\n",
      "    accuracy                           0.31      1046\n",
      "   macro avg       0.36      0.35      0.29      1046\n",
      "weighted avg       0.35      0.31      0.25      1046\n",
      "\n",
      "\n",
      "Final Results Summary:\n",
      "Endpoint: endpoint-resnet\n",
      "Accuracy: 27.53%\n",
      "Confusion Matrix:\n",
      "[[ 36   3  34  42   8]\n",
      " [ 11   5  46 112  56]\n",
      " [  5   1  40 132  89]\n",
      " [  2   1  33 120  82]\n",
      " [  2   0  24  75  87]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.29      0.40       123\n",
      "           2       0.50      0.02      0.04       230\n",
      "           3       0.23      0.15      0.18       267\n",
      "           4       0.25      0.50      0.33       238\n",
      "           5       0.27      0.46      0.34       188\n",
      "\n",
      "    accuracy                           0.28      1046\n",
      "   macro avg       0.38      0.29      0.26      1046\n",
      "weighted avg       0.35      0.28      0.24      1046\n",
      "\n",
      "\n",
      "Endpoint: endpoint-simple\n",
      "Accuracy: 28.68%\n",
      "Confusion Matrix:\n",
      "[[  7  54  54   7   1]\n",
      " [  1  38 124  48  19]\n",
      " [  1  14 132  98  22]\n",
      " [  1   9 123  77  28]\n",
      " [  1   5  63  73  46]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.06      0.10       123\n",
      "           2       0.32      0.17      0.22       230\n",
      "           3       0.27      0.49      0.35       267\n",
      "           4       0.25      0.32      0.28       238\n",
      "           5       0.40      0.24      0.30       188\n",
      "\n",
      "    accuracy                           0.29      1046\n",
      "   macro avg       0.37      0.26      0.25      1046\n",
      "weighted avg       0.34      0.29      0.27      1046\n",
      "\n",
      "\n",
      "Endpoint: endpoint-hpo\n",
      "Accuracy: 30.98%\n",
      "Confusion Matrix:\n",
      "[[ 60  49   2   3   9]\n",
      " [ 28 104   5  20  73]\n",
      " [ 16  98   8  19 126]\n",
      " [  7  60   1  22 148]\n",
      " [  6  34   3  15 130]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.49      0.50       123\n",
      "           2       0.30      0.45      0.36       230\n",
      "           3       0.42      0.03      0.06       267\n",
      "           4       0.28      0.09      0.14       238\n",
      "           5       0.27      0.69      0.39       188\n",
      "\n",
      "    accuracy                           0.31      1046\n",
      "   macro avg       0.36      0.35      0.29      1046\n",
      "weighted avg       0.35      0.31      0.25      1046\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sagemaker.predictor import Predictor\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Preprocessing pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define valid classes\n",
    "valid_classes = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Initialize results storage\n",
    "results = {}\n",
    "\n",
    "# List of endpoints and their names\n",
    "endpoints = {\n",
    "    \"endpoint-resnet\": Predictor(endpoint_name=\"endpoint-resnet\"),\n",
    "    \"endpoint-simple\": Predictor(endpoint_name=\"endpoint-simple\"),\n",
    "    \"endpoint-hpo\": Predictor(endpoint_name=\"endpoint-hpo\")\n",
    "}\n",
    "\n",
    "# Iterate through endpoints\n",
    "for endpoint_name, predictor in endpoints.items():\n",
    "    print(f\"Evaluating {endpoint_name}...\")\n",
    "\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over all test data\n",
    "    for class_label in valid_classes:  # Folders 1, 2, ..., 5\n",
    "        folder_path = os.path.join(\"./processed_data/test\", str(class_label))\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        for image_file in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_file)\n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "\n",
    "            # Open and preprocess the image\n",
    "            with open(image_path, \"rb\") as f:\n",
    "                payload = f.read()\n",
    "\n",
    "            # Make prediction\n",
    "            response = predictor.predict(payload, initial_args={\"ContentType\": \"image/jpeg\"})\n",
    "            predicted_class = int(np.array(eval(response.decode()))[0]) + 1  # Add 1 to align with valid_classes\n",
    "            \n",
    "            # Append true label and prediction\n",
    "            true_labels.append(class_label)\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "    # Validate class range\n",
    "    print(f\"Unique true labels: {set(true_labels)}\")\n",
    "    print(f\"Unique predicted labels: {set(predictions)}\")\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions, labels=valid_classes)\n",
    "    classification_report_str = classification_report(\n",
    "        true_labels, predictions, labels=valid_classes, target_names=[str(c) for c in valid_classes]\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Accuracy for {endpoint_name}: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Confusion Matrix for {endpoint_name}:\\n{conf_matrix}\")\n",
    "    print(f\"Classification Report for {endpoint_name}:\\n{classification_report_str}\")\n",
    "\n",
    "    # Store results\n",
    "    results[endpoint_name] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "        \"classification_report\": classification_report_str\n",
    "    }\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\nFinal Results Summary:\")\n",
    "for endpoint_name, metrics in results.items():\n",
    "    print(f\"Endpoint: {endpoint_name}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy'] * 100:.2f}%\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\")\n",
    "    print(f\"Classification Report:\\n{metrics['classification_report']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: endpoint-simple\n",
      "INFO:sagemaker:Deleting endpoint with name: endpoint-simple\n"
     ]
    }
   ],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "from sagemaker.predictor import Predictor\n",
    "predictor = Predictor(endpoint_name=\"endpoint-simple\")\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: endpoint-resnet\n",
      "INFO:sagemaker:Deleting endpoint with name: endpoint-resnet\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(endpoint_name=\"endpoint-resnet\")\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: endpoint-hpo\n",
      "INFO:sagemaker:Deleting endpoint with name: endpoint-hpo\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(endpoint_name=\"endpoint-hpo\")\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
